{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78cd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "1#dataset.py (adjust for R(2+1)D)\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from load_video_test import load_video\n",
    "\n",
    "class CricketVideoDataset(Dataset):\n",
    "    def _init_(self, root_dir, max_frames=64):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.video_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for cls in self.classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            for file in os.listdir(cls_path):\n",
    "                if file.endswith(\".mp4\"):\n",
    "                    self.video_paths.append(os.path.join(cls_path, file))\n",
    "                    self.labels.append(self.class_to_idx[cls])\n",
    "\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        video_path = self.video_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        video_tensor = load_video(video_path, self.max_frames)\n",
    "        return video_tensor, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b29c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class R2Plus1D(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(R2Plus1D, self).__init__()\n",
    "\n",
    "        # Example: first conv block (2D + 1D decomposition)\n",
    "        self.conv1_spatial = nn.Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3))\n",
    "        self.conv1_temporal = nn.Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "\n",
    "        # More layers can be added (ResNet-style)\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (B, 3, T, H, W)\n",
    "        x = F.relu(self.bn1(self.conv1_temporal(self.conv1_spatial(x))))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c87278",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'R2Plus1D' from 'model' (c:\\Users\\sanvi\\OneDrive\\Desktop\\main_project\\Action_Recognition_for_cricket_commentary\\cric proj\\model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CricketVideoDataset\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m R2Plus1D\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Dataset path\u001b[39;00m\n\u001b[0;32m      8\u001b[0m train_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msingh\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpratap\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcric proj\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcricket_dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'R2Plus1D' from 'model' (c:\\Users\\sanvi\\OneDrive\\Desktop\\main_project\\Action_Recognition_for_cricket_commentary\\cric proj\\model.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CricketVideoDataset\n",
    "from model import R2Plus1D\n",
    "\n",
    "\n",
    "# Dataset path\n",
    "train_dir = r\"C:\\Users\\singh\\pratap\\cric proj\\cricket_dataset\\train\"\n",
    "val_dir = r\"C:\\Users\\singh\\pratap\\cric proj\\cricket_dataset\\val\"\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 3\n",
    "batch_size = 2\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "max_frames = 64\n",
    "\n",
    "# Dataset & DataLoader\n",
    "train_dataset = CricketVideoDataset(train_dir, max_frames=max_frames)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = R2Plus1D_Cricket(num_classes=num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for videos, labels in train_loader:\n",
    "        videos = videos.permute(0, 2, 1, 3, 4).to(device)  # (B, T, C, H, W) -> (B, C, T, H, W)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"weights/r2plus1d_cricket.pth\")\n",
    "print(\"âœ… Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cricket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
